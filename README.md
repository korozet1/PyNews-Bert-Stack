# ğŸŒŒ BERT-News-Classifier | ä¸­æ–‡æ–°é—»æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ

<div align="center">
  <p>
    <b>åŸºäº BERT é¢„è®­ç»ƒæ¨¡å‹ä¸ PyTorch æ¡†æ¶çš„ä¼ä¸šçº§ä¸­æ–‡æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ</b>
  </p>


  ![PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange?style=flat-square)
  ![BERT](https://img.shields.io/badge/Model-BERT_Base_Chinese-yellow?style=flat-square)
  ![Flask](https://img.shields.io/badge/Microservice-Flask-green?style=flat-square)
  ![Streamlit](https://img.shields.io/badge/UI-Streamlit-red?style=flat-square)
  ![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square)
</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¸­æ–‡æ–°é—»æ–‡æœ¬åˆ†ç±»è§£å†³æ–¹æ¡ˆã€‚ä¸åŒäºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ SVMã€Bayesï¼‰ï¼Œæœ¬é¡¹ç›®åŸºäº Google å¼ºå¤§çš„ **BERT (Bidirectional Encoder Representations from Transformers)** é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ˆFine-tuningï¼‰ã€‚

ç³»ç»Ÿèƒ½å¤Ÿç²¾å‡†åœ°ç†è§£ä¸­æ–‡è¯­ä¹‰ï¼Œå¤„ç†é•¿éš¾å¥ï¼Œå¹¶åœ¨**é‡‘èã€ä½“è‚²ã€å¨±ä¹ã€ç§‘æŠ€**ç­‰ 10 ä¸ªæ–°é—»ç±»åˆ«ä¸Šå®ç°äº†æé«˜çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚é¡¹ç›®ä¸ä»…åŒ…å«æ ¸å¿ƒç®—æ³•è®­ç»ƒï¼Œè¿˜æä¾›äº† **RESTful API æœåŠ¡** å’Œ **å¯è§†åŒ– Web ç•Œé¢**ï¼Œå®ç°äº†ä»"ç®—æ³•ç ”å‘"åˆ°"å·¥ç¨‹è½åœ°"çš„å…¨æµç¨‹é—­ç¯ã€‚

æ­¤å¤–ï¼Œæœ¬é¡¹ç›®è¿˜å¼•å…¥äº†å¤šç§**æ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ–æŠ€æœ¯**ï¼ŒåŒ…æ‹¬ï¼š

- **çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰**ï¼šæ”¯æŒç¡¬æ ‡ç­¾è’¸é¦å’Œè½¯æ ‡ç­¾è’¸é¦ï¼Œå°† BERT æ•™å¸ˆæ¨¡å‹çŸ¥è¯†è¿ç§»åˆ°è½»é‡çº§ BiLSTM å­¦ç”Ÿæ¨¡å‹
- **æ¨¡å‹é‡åŒ–ï¼ˆQuantizationï¼‰**ï¼šFP32 åˆ° INT8 çš„åŠ¨æ€é‡åŒ–ï¼Œæ˜¾è‘—æå‡ CPU æ¨ç†é€Ÿåº¦
- **æ¨¡å‹å‰ªæï¼ˆPruningï¼‰**ï¼šå…¨å±€éç»“æ„åŒ–å‰ªæï¼ŒåŸºäº L1 èŒƒæ•°ç§»é™¤å†—ä½™æƒé‡ï¼Œå‡å°‘æ¨¡å‹è®¡ç®—é‡

è¿™äº›æŠ€æœ¯å¯æ ¹æ®ä¸åŒåœºæ™¯çµæ´»ç»„åˆä½¿ç”¨ï¼Œåœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶å¤§å¹…æå‡æ¨ç†æ•ˆç‡ã€‚

---

## ğŸ“‚ é¡¹ç›®ç›®å½•ç»“æ„

ç¡®ä¿ä½ çš„é¡¹ç›®æ–‡ä»¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œè¿™å¯¹äºç¨‹åºèƒ½æ­£ç¡®è¯»å–æ–‡ä»¶è‡³å…³é‡è¦ï¼š

```text
test-06/
â”œâ”€â”€ bert-base-chinese/          # [å…³é”®] å­˜æ”¾é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶çš„ç›®å½• (éœ€æ‰‹åŠ¨ä¸‹è½½)
â”‚   â”œâ”€â”€ config.json             # æ¨¡å‹æ¶æ„é…ç½®
â”‚   â”œâ”€â”€ pytorch_model.bin       # æ¨¡å‹æƒé‡æ–‡ä»¶ (çº¦400MB+)
â”‚   â”œâ”€â”€ vocab.txt               # è¯æ±‡è¡¨
â”‚   â”œâ”€â”€ tokenizer.json          # åˆ†è¯å™¨æ–‡ä»¶
â”‚   â””â”€â”€ tokenizer_config.json   # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ data/                       # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ class.txt               # ç±»åˆ«æ ‡ç­¾ (ä¸€è¡Œä¸€ä¸ª)
â”‚   â”œâ”€â”€ train.txt               # è®­ç»ƒé›† (æ ¼å¼: æ–‡æœ¬\tæ ‡ç­¾ID)
â”‚   â”œâ”€â”€ dev.txt                 # éªŒè¯é›†
â”‚   â”œâ”€â”€ test.txt                # æµ‹è¯•é›†
â”‚   â””â”€â”€ stopwords.txt           # åœç”¨è¯è¡¨
â”œâ”€â”€ save_models/                # [è‡ªåŠ¨ç”Ÿæˆ] BERTè®­ç»ƒç»“æœä¿å­˜ç›®å½•
â”‚   â””â”€â”€ test_bertclassifer_model.pt  # è®­ç»ƒå¥½çš„æœ€ä½³BERTæ¨¡å‹
â”œâ”€â”€ models_save/                # [è‡ªåŠ¨ç”Ÿæˆ] å­¦ç”Ÿæ¨¡å‹ä¿å­˜ç›®å½•
â”‚   â”œâ”€â”€ bilstm_hard_distill.pth  # ç¡¬æ ‡ç­¾è’¸é¦è®­ç»ƒçš„BiLSTMæ¨¡å‹
â”‚   â””â”€â”€ bilstm_soft_distill.pth  # è½¯æ ‡ç­¾è’¸é¦è®­ç»ƒçš„BiLSTMæ¨¡å‹
â”œâ”€â”€ config.py                   # å…¨å±€é…ç½®æ–‡ä»¶ (æ˜¾å¡ã€è·¯å¾„ã€è¶…å‚æ•°)
â”œâ”€â”€ bert_classifer_model.py     # BERTæ¨¡å‹æ¶æ„ä»£ç 
â”œâ”€â”€ bilstm_classifier.py        # BiLSTMå­¦ç”Ÿæ¨¡å‹æ¶æ„ä»£ç 
â”œâ”€â”€ train.py                    # BERTè®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ hard_label_distillation.py  # ç¡¬æ ‡ç­¾è’¸é¦è®­ç»ƒç¨‹åº
â”œâ”€â”€ soft_label_distillation.py  # è½¯æ ‡ç­¾è’¸é¦è®­ç»ƒç¨‹åº
â”œâ”€â”€ bert_model_quantization.py  # BERTæ¨¡å‹é‡åŒ–è„šæœ¬
â”œâ”€â”€ custom_pruning.py           # BERTæ¨¡å‹å‰ªæè„šæœ¬
â”œâ”€â”€ predict_fun.py              # å¸¸è§„æ¨¡å‹é¢„æµ‹å‡½æ•°
â”œâ”€â”€ predict_quantization.py     # é‡åŒ–æ¨¡å‹é¢„æµ‹å‡½æ•°
â”œâ”€â”€ api.py                      # åç«¯æ¥å£æœåŠ¡
â”œâ”€â”€ api_test.py                 # APIæµ‹è¯•è„šæœ¬
â”œâ”€â”€ app.py                      # å‰ç«¯å¯è§†åŒ–ç•Œé¢
â”œâ”€â”€ utils.py                    # æ•°æ®å¤„ç†å·¥å…·
â””â”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
```

---

## ğŸ› ï¸ ç¯å¢ƒæ­å»ºä¸é…ç½®

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼Œç¡®ä¿ç¯å¢ƒé…ç½®æ— è¯¯ã€‚

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

å»ºè®®ä½¿ç”¨ Anaconda ç®¡ç†ç¯å¢ƒï¼Œé˜²æ­¢ä¾èµ–å†²çªã€‚æ‰“å¼€ç»ˆç«¯ï¼ˆTerminal/Anaconda Promptï¼‰ï¼š

```bash
# 1. åˆ›å»ºåä¸º bert_env çš„è™šæ‹Ÿç¯å¢ƒï¼ŒæŒ‡å®š Python 3.8
conda create -n bert_env python=3.8

# 2. æ¿€æ´»ç¯å¢ƒ
conda activate bert_env
```

### ç¬¬äºŒæ­¥ï¼šå®‰è£…ä¾èµ–åŒ…

åœ¨æ¿€æ´»çš„ç¯å¢ƒä¸­ï¼Œå®‰è£…é¡¹ç›®æ‰€éœ€çš„ç¬¬ä¸‰æ–¹åº“ï¼š

```bash
# å®‰è£… PyTorch (å»ºè®®å»å®˜ç½‘ pytorch.org æ ¹æ®ä½ çš„æ˜¾å¡ç‰ˆæœ¬æ‰¾å¯¹åº”çš„å‘½ä»¤ï¼Œè¿™é‡Œæ˜¯é€šç”¨ç‰ˆ)
pip install torch torchvision torchaudio

# å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
pip install transformers flask streamlit scikit-learn tqdm requests
```

### ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ BERT é¢„è®­ç»ƒæ¨¡å‹

ç”±äºæ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡ 400MBï¼‰ï¼ŒGit æ— æ³•ç›´æ¥ä¸Šä¼ ï¼Œä½ éœ€è¦æ‰‹åŠ¨ä¸‹è½½ã€‚

1. **è®¿é—® Hugging Face ä»“åº“**:
   ğŸ‘‰ [https://huggingface.co/google-bert/bert-base-chinese/tree/main](https://huggingface.co/google-bert/bert-base-chinese/tree/main)

2. **ä¸‹è½½ä»¥ä¸‹ 3 ä¸ªæ ¸å¿ƒæ–‡ä»¶** (å…¶ä»– json æ–‡ä»¶å¯é€‰ï¼Œä½†è¿™ä¸‰ä¸ªå¿…é¡»æœ‰):
   - `config.json`
   - `pytorch_model.bin` (ç‚¹å‡»ä¸‹è½½æŒ‰é’®ï¼Œä¸è¦å³é”®å¦å­˜ä¸º)
   - `vocab.txt`

3. **æ”¾ç½®æ–‡ä»¶**:
   å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `bert-base-chinese/` æ–‡ä»¶å¤¹ä¸­ã€‚

### ç¬¬å››æ­¥ï¼šä¿®æ”¹é…ç½®

æ‰“å¼€ `config.py` æ–‡ä»¶ï¼Œæ ¹æ®ä½ çš„ç¡¬ä»¶æƒ…å†µè°ƒæ•´å‚æ•°ï¼š

```python
class Config(object):
    # ...

    # æ˜¾å­˜ä¼˜åŒ–ï¼šå¦‚æœä½ æ˜¯ 3090/4090 (24G)ï¼Œå¯ä»¥è®¾ä¸º 128 æˆ– 64
    # å¦‚æœä½ æ˜¯ 1660Ti/2060 (6G-8G)ï¼Œå»ºè®®è®¾ä¸º 16 æˆ– 32ï¼Œå¦åˆ™ä¼š OOM (æ˜¾å­˜æº¢å‡º)
    self.batch_size = 128

    # è®­ç»ƒè½®æ•°ï¼šé€šå¸¸ 2-5 è½®å³å¯æ”¶æ•›
    self.num_epochs = 2

    # ...
```

---

## ğŸš€ è¿è¡ŒæŒ‡å—

### åŸºç¡€è¿è¡Œæ¨¡å¼

#### 1. è®­ç»ƒ BERT æ•™å¸ˆæ¨¡å‹

è¿è¡Œè®­ç»ƒè„šæœ¬ï¼Œæ¨¡å‹å°†åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå¹¶å¼€å§‹åœ¨ä½ çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚

```bash
python train.py
```

> **ç°è±¡**: æ§åˆ¶å°ä¼šå‡ºç°è¿›åº¦æ¡ï¼Œæ˜¾ç¤º Loss é€æ¸ä¸‹é™ã€‚è®­ç»ƒç»“æŸåï¼Œæœ€ä½³æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ `save_models/test_bertclassifer_model.pt`ã€‚

#### 2. å¯åŠ¨åç«¯ API æœåŠ¡

å¦‚æœä½ éœ€è¦é€šè¿‡æ¥å£è°ƒç”¨æ¨¡å‹ï¼Œè¯·å¯åŠ¨ Flask æœåŠ¡ã€‚

```bash
python api.py
```

> **ç°è±¡**: æ§åˆ¶å°æ˜¾ç¤º `Running on http://0.0.0.0:8004`ã€‚æ­¤æ—¶æœåŠ¡å·²æŒ‚èµ·ï¼Œç­‰å¾…è¯·æ±‚ã€‚

#### 3. å¯åŠ¨å‰ç«¯å¯è§†åŒ–ç•Œé¢

**æ³¨æ„**: åœ¨å¯åŠ¨å‰ç«¯ä¹‹å‰ï¼Œ**å¿…é¡»å…ˆå¯åŠ¨ api.py**ï¼Œå› ä¸ºå‰ç«¯éœ€è¦è°ƒç”¨åç«¯çš„æ¥å£ã€‚

ä¿æŒä¸Šé¢çš„ç»ˆç«¯ä¸å…³é—­ï¼Œæ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯çª—å£ï¼š

```bash
# è®°å¾—å…ˆæ¿€æ´»ç¯å¢ƒ: conda activate bert_env
streamlit run app.py
```

> **ç°è±¡**: æµè§ˆå™¨ä¼šè‡ªåŠ¨å¼¹å‡ºï¼Œä½ å¯ä»¥åœ¨ç½‘é¡µæ–‡æœ¬æ¡†ä¸­è¾“å…¥æ–°é—»æ ‡é¢˜ï¼Œç‚¹å‡»"é¢„æµ‹"æŒ‰é’®æŸ¥çœ‹ç»“æœã€‚

---

### çŸ¥è¯†è’¸é¦æ¨¡å¼

çŸ¥è¯†è’¸é¦æŠ€æœ¯å¯å°†å¤§æ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°å°æ¨¡å‹ï¼Œåœ¨ä¿æŒè¾ƒé«˜ç²¾åº¦çš„åŒæ—¶æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ã€‚

#### 1. ç¡¬æ ‡ç­¾è’¸é¦ï¼ˆHard Label Distillationï¼‰

ç¡¬æ ‡ç­¾è’¸é¦è®©å­¦ç”Ÿæ¨¡å‹ç›´æ¥å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹ç±»åˆ«ã€‚

```bash
python hard_label_distillation.py
```

> **è¯´æ˜**: ç¨‹åºä¼šè‡ªåŠ¨åŠ è½½è®­ç»ƒå¥½çš„ BERT æ¨¡å‹ä½œä¸ºæ•™å¸ˆï¼Œè®­ç»ƒ BiLSTM å­¦ç”Ÿæ¨¡å‹ï¼Œå°†è½¯æ ‡ç­¾å’Œç¡¬æ ‡ç­¾æŸå¤±ç»“åˆï¼Œè’¸é¦åçš„æ¨¡å‹ä¿å­˜åœ¨ `models_save/bilstm_hard_distill.pth`ã€‚

#### 2. è½¯æ ‡ç­¾è’¸é¦ï¼ˆSoft Label Distillationï¼‰

è½¯æ ‡ç­¾è’¸é¦è®©å­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„æ¦‚ç‡åˆ†å¸ƒï¼Œèƒ½å¤Ÿä¼ é€’æ›´ä¸°å¯Œçš„çŸ¥è¯†ã€‚

```bash
python soft_label_distillation.py
```

> **è¯´æ˜**: ç¨‹åºä½¿ç”¨ KL æ•£åº¦æŸå¤±ç»“åˆç¡¬æ ‡ç­¾æŸå¤±ï¼Œæ¸©åº¦å‚æ•° T=2.0ï¼Œalpha=0.7ï¼Œè’¸é¦åçš„æ¨¡å‹ä¿å­˜åœ¨ `models_save/bilstm_soft_distill.pth`ã€‚

#### 3. å­¦ç”Ÿæ¨¡å‹é¢„æµ‹

ä½¿ç”¨è’¸é¦åçš„è½»é‡çº§ BiLSTM æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«ï¼š

```bash
python predict_fun.py
```

> **ä¼˜åŠ¿**: BiLSTM å­¦ç”Ÿæ¨¡å‹ç›¸æ¯” BERT æ•™å¸ˆæ¨¡å‹ï¼Œæ¨ç†é€Ÿåº¦æå‡ 5-10 å€ï¼Œé€‚åˆå®æ—¶åº”ç”¨åœºæ™¯ã€‚

---

### æ¨¡å‹é‡åŒ–æ¨¡å¼

é‡åŒ–åŠŸèƒ½å¯æ˜¾è‘—æå‡ CPU æ¨ç†é€Ÿåº¦ï¼Œé€‚ç”¨äºè¾¹ç¼˜éƒ¨ç½²åœºæ™¯ã€‚

#### 1. æ¨¡å‹é‡åŒ–

è¿è¡Œè„šæœ¬å°† FP32 æƒé‡å‹ç¼©ä¸º INT8 æ ¼å¼ï¼š

```bash
python bert_model_quantization.py
```

#### 2. é‡åŒ–é¢„æµ‹æ¨ç†

é‡åŒ–ç®—å­ç›®å‰ä»…æ”¯æŒ CPUï¼Œæ¨ç†æ—¶éœ€å¼ºåˆ¶æŒ‡å®š `device='cpu'`ï¼š

```bash
python predict_quantization.py
```

---

### æ¨¡å‹å‰ªææ¨¡å¼

å‰ªææŠ€æœ¯é€šè¿‡ç§»é™¤æ¨¡å‹ä¸­çš„å†—ä½™æƒé‡ï¼Œå‡å°‘æ¨¡å‹è®¡ç®—é‡ï¼Œåœ¨ä¿æŒè¾ƒé«˜ç²¾åº¦çš„åŒæ—¶æå‡æ¨ç†é€Ÿåº¦ã€‚

#### 1. å…¨å±€éç»“æ„åŒ–å‰ªæ

è¿è¡Œè„šæœ¬å¯¹ BERT æ‰€æœ‰ encoder å±‚çš„æ³¨æ„åŠ›æƒé‡è¿›è¡Œ L1 èŒƒæ•°å‰ªæï¼š

```bash
python custom_pruning.py
```

> **è¯´æ˜**: ç¨‹åºä¼šå¯¹æ‰€æœ‰ 12 å±‚ encoder çš„ query æƒé‡è¿›è¡Œ 30% çš„éç»“æ„åŒ–å‰ªæï¼Œè¾“å‡ºå‰ªæå‰åçš„å‡†ç¡®ç‡å¯¹æ¯”å’Œç¨€ç–åº¦æŒ‡æ ‡ï¼Œå‰ªæåçš„æ¨¡å‹ä¿å­˜åœ¨ `models_save/pruned_model.pth`ã€‚

**å‰ªææ•ˆæœ**:

- å‰ªææ¯”ä¾‹ï¼š30%ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
- å‰ªææ–¹æ³•ï¼šL1 èŒƒæ•°å…¨å±€éç»“æ„åŒ–å‰ªæ
- å‰ªæå¯¹è±¡ï¼šBERT encoder å±‚çš„ query æƒé‡
- ç¨€ç–åº¦ï¼šçº¦ 30% æƒé‡è¢«ç½®ä¸º 0
- æ€§èƒ½å½±å“ï¼šå‡†ç¡®ç‡ä¸‹é™é€šå¸¸å°äº 1-2%ï¼Œæ¨ç†é€Ÿåº¦æå‡ 10-20%

---

## ğŸ“¡ API æ¥å£æ–‡æ¡£

å¦‚æœä½ æƒ³å°†æ­¤æ¨¡å‹é›†æˆåˆ°å…¶ä»–ç³»ç»Ÿï¼ˆå¦‚ Java/Go åç«¯ï¼‰ï¼Œè¯·å‚è€ƒä»¥ä¸‹æ¥å£è§„èŒƒã€‚

**æœåŠ¡åœ°å€**: `http://127.0.0.1:8004`

### æ–‡æœ¬åˆ†ç±»æ¥å£

- **URL Endpoint**: `/predict`
- **Method**: `POST`
- **Content-Type**: `application/json`

**è¯·æ±‚ä½“ç¤ºä¾‹:**

```json
{
    "text": "SpaceX æ˜Ÿèˆ°ä»Šæ—¥æˆåŠŸå‘å°„ï¼Œå¼€å¯ç«æ˜Ÿç§»æ°‘æ–°ç¯‡ç« "
}
```

**å“åº”ä½“ç¤ºä¾‹:**

```json
{
    "text": "SpaceX æ˜Ÿèˆ°ä»Šæ—¥æˆåŠŸå‘å°„...",
    "pred_class": "ç§‘æŠ€",
    "status": 200
}
```

è¯¦æƒ…è¯·å‚è€ƒ `api.py` ä¸­çš„å…·ä½“å®ç°ã€‚

---

## ğŸ’¡ æŠ€æœ¯æ·±åº¦æ€»ç»“

### æ¨¡å‹é‡åŒ–ç»éªŒ

åœ¨å¼€å‘æ¨¡å‹å‹ç¼©ä¸é‡åŒ–åŠŸèƒ½æ—¶ï¼Œæœ¬é¡¹ç›®æ€»ç»“äº†ä»¥ä¸‹ PyTorch æ ¸å¿ƒç»éªŒï¼š

1. **ä¸¤ç§ä¿å­˜æ–¹å¼çš„æƒè¡¡**
   - **`state_dict` (æ¨è)**: ä»…ä¿å­˜å‚æ•°å­—å…¸ï¼Œæ–‡ä»¶ä½“ç§¯æœ€å°ã€‚ä¸ä¾èµ–ä»£ç ç›®å½•ç»“æ„ï¼Œè·¨è®¾å¤‡å…¼å®¹æ€§æœ€å¼ºã€‚
   - **å…¨æ¨¡å‹ä¿å­˜**: ä¿å­˜æ•´ä¸ªæ¨¡å‹å¯¹è±¡ã€‚ç”±äºé‡åŒ–åå±‚ç»“æ„å˜å¼‚ï¼Œå­˜å…¨é‡å¯é¿å…æ‰‹åŠ¨æ‰§è¡Œé‡åŒ–æµç¨‹ï¼Œä½†å¯¹æ–‡ä»¶å¤¹è·¯å¾„æœ‰æå¼ºä¾èµ–ã€‚

2. **é‡åŒ–æ¨¡å‹çš„åŠ è½½é€»è¾‘**
   - **ç—›ç‚¹**: é‡åŒ–æ¨¡å‹åŒ…å«é¢å¤–çš„ `scale` å’Œ `zero_point` å‚æ•°ã€‚
   - **æ­£ç¡®é¡ºåº**: å¦‚æœåŠ è½½çš„æ˜¯é‡åŒ–åçš„å‚æ•°å­—å…¸ï¼Œå¿…é¡»å…ˆå®ä¾‹åŒ–åŸå§‹æ¨¡å‹ï¼Œç„¶åæ‰‹åŠ¨æ‰§è¡Œ `quantize_dynamic` è®©ç»“æ„"å˜å¼‚"ï¼Œæœ€åé€šè¿‡ `load_state_dict` æ³¨å…¥å‚æ•°ã€‚
   - **æŠ¥é”™é¢„é˜²**: è‹¥ç›´æ¥å°†é‡åŒ–å‚æ•°åŠ è½½è¿›éé‡åŒ–å£³å­ï¼Œä¼šè§¦å‘ `KeyError` é”™è¯¯ã€‚

3. **è®¡ç®—è®¾å¤‡çº¦æŸ**
   - **CPU ä¸“å±**: é‡åŒ–ç®—å­ç›®å‰ä»…æ³¨å†Œåœ¨ CPU ç«¯ï¼Œåœ¨ GPU ä¸Šè¿è¡Œé‡åŒ–æ¨¡å‹ä¼šæŠ›å‡º `NotImplementedError`ã€‚
   - **è§£å†³æ–¹æ¡ˆ**: åœ¨é¢„æµ‹è„šæœ¬ä¸­å¿…é¡»å¼ºåˆ¶æŒ‡å®š `device = 'cpu'`ï¼Œå¹¶å°†è¾“å…¥ Tensor åŒæ­¥ç§»è‡³ CPU å†…å­˜ã€‚

### çŸ¥è¯†è’¸é¦ç»éªŒ

1. **è’¸é¦ç­–ç•¥é€‰æ‹©**
   - **ç¡¬æ ‡ç­¾è’¸é¦**: ç®€å•ç›´æ¥ï¼Œé€‚åˆå¯¹æ¨ç†é€Ÿåº¦è¦æ±‚æé«˜çš„åœºæ™¯ã€‚
   - **è½¯æ ‡ç­¾è’¸é¦**: é€šè¿‡æ¸©åº¦å‚æ•°å¹³æ»‘æ¦‚ç‡åˆ†å¸ƒï¼Œä¼ é€’æ›´ä¸°å¯Œçš„çŸ¥è¯†ï¼Œé€šå¸¸èƒ½è·å¾—æ›´å¥½çš„ç²¾åº¦ã€‚

2. **è¶…å‚æ•°è°ƒä¼˜**
   - **æ¸©åº¦å‚æ•° T**: ä¸€èˆ¬è®¾ç½®ä¸º 2.0-5.0ï¼ŒT è¶Šå¤§ï¼Œæ¦‚ç‡åˆ†å¸ƒè¶Šå¹³æ»‘ã€‚
   - **æƒé‡ alpha**: è½¯æ ‡ç­¾æŸå¤±æƒé‡ï¼Œé€šå¸¸è®¾ç½®ä¸º 0.5-0.9ï¼Œå¹³è¡¡è½¯ç¡¬æ ‡ç­¾æŸå¤±ã€‚

3. **æ€§èƒ½å¯¹æ¯”**
   - **ç²¾åº¦**: BERT æ•™å¸ˆæ¨¡å‹ > è½¯æ ‡ç­¾è’¸é¦å­¦ç”Ÿæ¨¡å‹ > ç¡¬æ ‡ç­¾è’¸é¦å­¦ç”Ÿæ¨¡å‹
   - **é€Ÿåº¦**: BiLSTM å­¦ç”Ÿæ¨¡å‹ >> BERT æ•™å¸ˆæ¨¡å‹ (5-10å€æå‡)

### æ¨¡å‹å‰ªæç»éªŒ

1. **å‰ªæç­–ç•¥é€‰æ‹©**
   - **éç»“æ„åŒ–å‰ªæ**: éšæœºæˆ–åŸºäºèŒƒæ•°å‰ªæå•ä¸ªæƒé‡ï¼Œç¨€ç–åº¦é«˜ä½†ç¡¬ä»¶æ”¯æŒæœ‰é™ã€‚
   - **ç»“æ„åŒ–å‰ªæ**: å‰ªææ•´ä¸ªé€šé“æˆ–ç¥ç»å…ƒï¼Œç¡¬ä»¶å‹å¥½ä½†ç²¾åº¦æŸå¤±ç›¸å¯¹è¾ƒå¤§ã€‚
   - **æ¸è¿›å¼å‰ªæ**: é€æ­¥å¢åŠ å‰ªææ¯”ä¾‹ï¼Œæ¨¡å‹é€‚åº”æ€§æ›´å¥½ã€‚

2. **å‰ªæå‚æ•°è°ƒä¼˜**
   - **å‰ªææ¯”ä¾‹**: ä¸€èˆ¬è®¾ç½®ä¸º 20-50%ï¼Œè¿‡é«˜ä¼šæ˜¾è‘—å½±å“ç²¾åº¦ã€‚
   - **å‰ªææ–¹æ³•**: L1/L2 èŒƒæ•°ã€æ¢¯åº¦ä¿¡æ¯ã€é‡è¦æ€§è¯„åˆ†ç­‰ã€‚
   - **å‰ªæèŒƒå›´**: å¯é€‰æ‹©å…¨æ¨¡å‹å‰ªææˆ–ç‰¹å®šå±‚å‰ªæï¼ˆå¦‚ attention å±‚ï¼‰ã€‚

3. **å‰ªæä¸é‡åŒ–ç»„åˆ**
   - **å‰ªæåé‡åŒ–**: å…ˆå‰ªæå†é‡åŒ–ï¼Œå¯è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ã€‚
   - **ååŒä¼˜åŒ–**: å‰ªæå’Œé‡åŒ–å¯ç›¸äº’é…åˆï¼Œå®ç°æœ€ä½³æ€§èƒ½å¹³è¡¡ã€‚
   - **å®éªŒå»ºè®®**: å¯¹æ¯”ä¸åŒå‰ªææ¯”ä¾‹å’Œé‡åŒ–ç²¾åº¦çš„ç»„åˆæ•ˆæœã€‚

4. **æ€§èƒ½è¯„ä¼°**
   - **ç¨€ç–åº¦**: å‰ªæåæ¨¡å‹ä¸­ 0 æƒé‡çš„å æ¯”ã€‚
   - **FLOPs å‡å°‘**: å‰ªæå¯å‡å°‘çš„è®¡ç®—é‡ã€‚
   - **ç²¾åº¦æŸå¤±**: å‰ªæåæ¨¡å‹ç²¾åº¦ä¸‹é™å¹…åº¦ï¼ˆé€šå¸¸å°äº 2-3%ï¼‰ã€‚

---

## â“ å¸¸è§é—®é¢˜

**Q1: æ˜¾å­˜æº¢å‡º (OOM) æ€ä¹ˆåŠï¼Ÿ**

A: è¯´æ˜æ˜¾å­˜çˆ†äº†ã€‚è¯·æ‰“å¼€ `config.py`ï¼Œå°† `self.batch_size` ä» 128 æ”¹ä¸º 64ï¼Œç”šè‡³ 32 æˆ– 16ã€‚

**Q2: æŠ¥é”™ `OSError: Can't load weights for 'bert-base-chinese'` æ€ä¹ˆåŠï¼Ÿ**

A: è¯´æ˜ä½ çš„ `bert-base-chinese` æ–‡ä»¶å¤¹é‡Œç¼ºå°‘æ–‡ä»¶ï¼Œæˆ–è€…æ–‡ä»¶åä¸å¯¹ã€‚è¯·æ£€æŸ¥æ˜¯å¦åŒ…å«äº† `pytorch_model.bin` ç­‰æ–‡ä»¶ï¼Œä¸”è·¯å¾„æ­£ç¡®ã€‚

**Q3: è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢ï¼Ÿ**

A: è¯·ç¡®ä¿ä½ å®‰è£…çš„æ˜¯ GPU ç‰ˆæœ¬çš„ PyTorchï¼Œå¹¶ä¸” `config.py` ä¸­çš„ `device` è¢«æ­£ç¡®è¯†åˆ«ä¸º `cuda`ã€‚

**Q4: ç¡¬æ ‡ç­¾è’¸é¦å’Œè½¯æ ‡ç­¾è’¸é¦æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

A: ç¡¬æ ‡ç­¾è’¸é¦åªä½¿ç”¨æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹ç±»åˆ«ï¼ˆargmaxï¼‰ï¼Œç®€å•å¿«é€Ÿï¼›è½¯æ ‡ç­¾è’¸é¦ä½¿ç”¨æ•™å¸ˆæ¨¡å‹çš„å®Œæ•´æ¦‚ç‡åˆ†å¸ƒï¼ˆé€šè¿‡æ¸©åº¦å‚æ•°è½¯åŒ–ï¼‰ï¼Œèƒ½ä¼ é€’æ›´å¤šçŸ¥è¯†ï¼Œé€šå¸¸ç²¾åº¦æ›´é«˜ã€‚

**Q5: å­¦ç”Ÿæ¨¡å‹ç›¸æ¯” BERT æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ**

A: BiLSTM å­¦ç”Ÿæ¨¡å‹å‚æ•°é‡è¿œå°äº BERTï¼ˆçº¦ 1/10ï¼‰ï¼Œæ¨ç†é€Ÿåº¦æå‡ 5-10 å€ï¼Œæ˜¾å­˜å ç”¨å¤§å¹…é™ä½ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡å’Œå®æ—¶åº”ç”¨åœºæ™¯ã€‚

**Q6: æ¨¡å‹å‰ªæå’Œé‡åŒ–æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

A: å‰ªæé€šè¿‡ç§»é™¤å†—ä½™æƒé‡å‡å°‘æ¨¡å‹è®¡ç®—é‡ï¼Œé‡åŒ–é€šè¿‡é™ä½æ•°å€¼ç²¾åº¦å‡å°‘æ¨¡å‹å¤§å°å’Œå†…å­˜å ç”¨ã€‚ä¸¤è€…å¯ä»¥ç»“åˆä½¿ç”¨ï¼Œå®ç°æ›´å¥½çš„å‹ç¼©æ•ˆæœã€‚

**Q7: å‰ªæåæ¨¡å‹ç²¾åº¦ä¸‹é™æ€ä¹ˆåŠï¼Ÿ**

A: å¯ä»¥å°è¯•ï¼šâ‘  é™ä½å‰ªææ¯”ä¾‹ï¼ˆä» 30% é™åˆ° 20%ï¼‰ï¼›â‘¡ ä½¿ç”¨ç»“æ„åŒ–å‰ªææ›¿ä»£éç»“æ„åŒ–å‰ªæï¼›â‘¢ å‰ªæåè¿›è¡Œå¾®è°ƒè®­ç»ƒæ¢å¤ç²¾åº¦ï¼›â‘£ é‡‡ç”¨æ¸è¿›å¼å‰ªæé€æ­¥å¢åŠ å‰ªææ¯”ä¾‹ã€‚

**Q8: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹å‹ç¼©ç­–ç•¥ï¼Ÿ**

A: æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©ï¼šCPU ç«¯ä¼˜å…ˆé‡åŒ–ï¼ˆé€Ÿåº¦æå‡æ˜æ˜¾ï¼‰ï¼Œè¾¹ç¼˜è®¾å¤‡ä¼˜å…ˆè’¸é¦ï¼ˆæ¨¡å‹æ›´å°ï¼‰ï¼ŒFPGA/ASIC ä¼˜å…ˆå‰ªæï¼ˆç¡¬ä»¶æ”¯æŒç¨€ç–è®¡ç®—ï¼‰ã€‚å»ºè®®è¿›è¡Œ A/B æµ‹è¯•ï¼Œå¯¹æ¯”ä¸åŒç»„åˆçš„æ€§èƒ½è¡¨ç°ã€‚

---

## ğŸ“„ ç‰ˆæƒè¯´æ˜

æœ¬é¡¹ç›®é‡‡ç”¨ MIT å¼€æºåè®®ã€‚

> 2026 Â© Developed by BERT-Team
