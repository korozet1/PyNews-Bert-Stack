# ğŸŒŒ BERT-News-Classifier | ä¸­æ–‡æ–°é—»æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ

<div align="center">
  <p>
    <b>åŸºäº BERT é¢„è®­ç»ƒæ¨¡å‹ä¸ PyTorch æ¡†æ¶çš„ä¼ä¸šçº§ä¸­æ–‡æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ</b>
  </p>


  ![PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange?style=flat-square)
  ![BERT](https://img.shields.io/badge/Model-BERT_Base_Chinese-yellow?style=flat-square)
  ![Flask](https://img.shields.io/badge/Microservice-Flask-green?style=flat-square)
  ![Streamlit](https://img.shields.io/badge/UI-Streamlit-red?style=flat-square)
  ![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square)
</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹ (Introduction)

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¸­æ–‡æ–°é—»æ–‡æœ¬åˆ†ç±»è§£å†³æ–¹æ¡ˆã€‚ä¸åŒäºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ SVMã€Bayesï¼‰ï¼Œæœ¬é¡¹ç›®åŸºäº Google å¼ºå¤§çš„ **BERT (Bidirectional Encoder Representations from Transformers)** é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼ˆFine-tuningï¼‰ã€‚

ç³»ç»Ÿèƒ½å¤Ÿç²¾å‡†åœ°ç†è§£ä¸­æ–‡è¯­ä¹‰ï¼Œå¤„ç†é•¿éš¾å¥ï¼Œå¹¶åœ¨**é‡‘èã€ä½“è‚²ã€å¨±ä¹ã€ç§‘æŠ€**ç­‰ 10 ä¸ªæ–°é—»ç±»åˆ«ä¸Šå®ç°äº†æé«˜çš„åˆ†ç±»å‡†ç¡®ç‡ã€‚é¡¹ç›®ä¸ä»…åŒ…å«æ ¸å¿ƒç®—æ³•è®­ç»ƒï¼Œè¿˜æä¾›äº† **RESTful API æœåŠ¡** å’Œ **å¯è§†åŒ– Web ç•Œé¢**ï¼Œå®ç°äº†ä»â€œç®—æ³•ç ”å‘â€åˆ°â€œå·¥ç¨‹è½åœ°â€çš„å…¨æµç¨‹é—­ç¯ã€‚

---

## ğŸ“‚ é¡¹ç›®ç›®å½•ç»“æ„ (Directory Structure)

ç¡®ä¿ä½ çš„é¡¹ç›®æ–‡ä»¶ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œè¿™å¯¹äºç¨‹åºèƒ½æ­£ç¡®è¯»å–æ–‡ä»¶è‡³å…³é‡è¦ï¼š

```text
test-04/
â”œâ”€â”€ bert-base-chinese/          # [å…³é”®] å­˜æ”¾é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶çš„ç›®å½• (éœ€æ‰‹åŠ¨ä¸‹è½½)
â”‚   â”œâ”€â”€ config.json             # æ¨¡å‹æ¶æ„é…ç½®
â”‚   â”œâ”€â”€ pytorch_model.bin       # æ¨¡å‹æƒé‡æ–‡ä»¶ (çº¦400MB+)
â”‚   â”œâ”€â”€ vocab.txt               # è¯æ±‡è¡¨
â”‚   â”œâ”€â”€ tokenizer.json          # åˆ†è¯å™¨æ–‡ä»¶
â”‚   â””â”€â”€ tokenizer_config.json   # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ data/                       # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ class.txt               # ç±»åˆ«æ ‡ç­¾ (ä¸€è¡Œä¸€ä¸ª)
â”‚   â”œâ”€â”€ train.txt               # è®­ç»ƒé›† (æ ¼å¼: æ–‡æœ¬\tæ ‡ç­¾ID)
â”‚   â”œâ”€â”€ dev.txt                 # éªŒè¯é›†
â”‚   â”œâ”€â”€ test.txt                # æµ‹è¯•é›†
â”‚   â””â”€â”€ stopwords.txt           # åœç”¨è¯è¡¨
â”œâ”€â”€ save_models/                # [è‡ªåŠ¨ç”Ÿæˆ] è®­ç»ƒç»“æœä¿å­˜ç›®å½•
â”‚   â””â”€â”€ test_bertclassifer_model.pt  # è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
â”œâ”€â”€ config.py                   # å…¨å±€é…ç½®æ–‡ä»¶ (æ˜¾å¡ã€è·¯å¾„ã€è¶…å‚æ•°)
â”œâ”€â”€ bert_classifer_model.py     # æ¨¡å‹æ¶æ„ä»£ç 
â”œâ”€â”€ train.py                    # è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ api.py                      # åç«¯æ¥å£æœåŠ¡
â”œâ”€â”€ app.py                      # å‰ç«¯å¯è§†åŒ–ç•Œé¢
â”œâ”€â”€ utils.py                    # æ•°æ®å¤„ç†å·¥å…·
â””â”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
```

---

## ğŸ› ï¸ ç¯å¢ƒæ­å»ºä¸é…ç½® (Setup Guide)

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼Œç¡®ä¿ç¯å¢ƒé…ç½®æ— è¯¯ã€‚

### ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (Conda)

å»ºè®®ä½¿ç”¨ Anaconda ç®¡ç†ç¯å¢ƒï¼Œé˜²æ­¢ä¾èµ–å†²çªã€‚æ‰“å¼€ç»ˆç«¯ï¼ˆTerminal/Anaconda Promptï¼‰ï¼š

```bash
# 1. åˆ›å»ºåä¸º bert_env çš„è™šæ‹Ÿç¯å¢ƒï¼ŒæŒ‡å®š Python 3.8
conda create -n bert_env python=3.8

# 2. æ¿€æ´»ç¯å¢ƒ
conda activate bert_env
```

### ç¬¬äºŒæ­¥ï¼šå®‰è£…ä¾èµ–åŒ… (Pip)

åœ¨æ¿€æ´»çš„ç¯å¢ƒä¸­ï¼Œå®‰è£…é¡¹ç›®æ‰€éœ€çš„ç¬¬ä¸‰æ–¹åº“ï¼š

```bash
# å®‰è£… PyTorch (å»ºè®®å»å®˜ç½‘ pytorch.org æ ¹æ®ä½ çš„æ˜¾å¡ç‰ˆæœ¬æ‰¾å¯¹åº”çš„å‘½ä»¤ï¼Œè¿™é‡Œæ˜¯é€šç”¨ç‰ˆ)
pip install torch torchvision torchaudio

# å®‰è£…å…¶ä»–æ ¸å¿ƒä¾èµ–
pip install transformers flask streamlit scikit-learn tqdm requests
```

### ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ BERT é¢„è®­ç»ƒæ¨¡å‹ (æœ€å…³é”®!)

ç”±äºæ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡ 400MBï¼‰ï¼ŒGit æ— æ³•ç›´æ¥ä¸Šä¼ ï¼Œä½ éœ€è¦æ‰‹åŠ¨ä¸‹è½½ã€‚

1.  **è®¿é—® Hugging Face ä»“åº“**:
    ğŸ‘‰ [https://huggingface.co/google-bert/bert-base-chinese/tree/main](https://huggingface.co/google-bert/bert-base-chinese/tree/main)

2.  **ä¸‹è½½ä»¥ä¸‹ 3 ä¸ªæ ¸å¿ƒæ–‡ä»¶** (å…¶ä»– json æ–‡ä»¶å¯é€‰ï¼Œä½†è¿™ä¸‰ä¸ªå¿…é¡»æœ‰):
    * `config.json`
    * `pytorch_model.bin` (ç‚¹å‡»ä¸‹è½½æŒ‰é’®ï¼Œä¸è¦å³é”®å¦å­˜ä¸º)
    * `vocab.txt`

3.  **æ”¾ç½®æ–‡ä»¶**:
    å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `bert-base-chinese/` æ–‡ä»¶å¤¹ä¸­ã€‚

### ç¬¬å››æ­¥ï¼šä¿®æ”¹é…ç½® (Config)

æ‰“å¼€ `config.py` æ–‡ä»¶ï¼Œæ ¹æ®ä½ çš„ç¡¬ä»¶æƒ…å†µè°ƒæ•´å‚æ•°ï¼š

```python
class Config(object):
    # ...
    
    # æ˜¾å­˜ä¼˜åŒ–ï¼šå¦‚æœä½ æ˜¯ 3090/4090 (24G)ï¼Œå¯ä»¥è®¾ä¸º 128 æˆ– 64
    # å¦‚æœä½ æ˜¯ 1660Ti/2060 (6G-8G)ï¼Œå»ºè®®è®¾ä¸º 16 æˆ– 32ï¼Œå¦åˆ™ä¼š OOM (æ˜¾å­˜æº¢å‡º)
    self.batch_size = 128 
    
    # è®­ç»ƒè½®æ•°ï¼šé€šå¸¸ 2-5 è½®å³å¯æ”¶æ•›
    self.num_epochs = 2
    
    # ...
```

---

## ğŸš€ è¿è¡ŒæŒ‡å— (How to Run)

### 1. å¼€å§‹è®­ç»ƒ (Train)

è¿è¡Œè®­ç»ƒè„šæœ¬ï¼Œæ¨¡å‹å°†åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå¹¶å¼€å§‹åœ¨ä½ çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚

```bash
python train.py
```

> **ç°è±¡**: æ§åˆ¶å°ä¼šå‡ºç°è¿›åº¦æ¡ï¼Œæ˜¾ç¤º Loss é€æ¸ä¸‹é™ã€‚è®­ç»ƒç»“æŸåï¼Œæœ€ä½³æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ `save_models/test_bertclassifer_model.pt`ã€‚

### 2. å¯åŠ¨åç«¯ API æœåŠ¡ (Backend)

å¦‚æœä½ éœ€è¦é€šè¿‡æ¥å£è°ƒç”¨æ¨¡å‹ï¼Œè¯·å¯åŠ¨ Flask æœåŠ¡ã€‚

```bash
python api.py
```

> **ç°è±¡**: æ§åˆ¶å°æ˜¾ç¤º `Running on http://0.0.0.0:8004`ã€‚æ­¤æ—¶æœåŠ¡å·²æŒ‚èµ·ï¼Œç­‰å¾…è¯·æ±‚ã€‚

### 3. å¯åŠ¨å‰ç«¯å¯è§†åŒ–ç•Œé¢ (Frontend)

**æ³¨æ„**: åœ¨å¯åŠ¨å‰ç«¯ä¹‹å‰ï¼Œ**å¿…é¡»å…ˆå¯åŠ¨ api.py**ï¼Œå› ä¸ºå‰ç«¯éœ€è¦è°ƒç”¨åç«¯çš„æ¥å£ã€‚
ä¿æŒä¸Šé¢çš„ç»ˆç«¯ä¸å…³é—­ï¼Œæ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯çª—å£ï¼š

```bash
# è®°å¾—å…ˆæ¿€æ´»ç¯å¢ƒ: conda activate bert_env
streamlit run app.py
```

> **ç°è±¡**: æµè§ˆå™¨ä¼šè‡ªåŠ¨å¼¹å‡ºï¼Œä½ å¯ä»¥åœ¨ç½‘é¡µæ–‡æœ¬æ¡†ä¸­è¾“å…¥æ–°é—»æ ‡é¢˜ï¼Œç‚¹å‡»â€œé¢„æµ‹â€æŒ‰é’®æŸ¥çœ‹ç»“æœã€‚

---

## ğŸ“¡ API æ¥å£æ–‡æ¡£ (API Documentation)

å¦‚æœä½ æƒ³å°†æ­¤æ¨¡å‹é›†æˆåˆ°å…¶ä»–ç³»ç»Ÿï¼ˆå¦‚ Java/Go åç«¯ï¼‰ï¼Œè¯·å‚è€ƒä»¥ä¸‹æ¥å£è§„èŒƒã€‚

**æœåŠ¡åœ°å€**: `http://127.0.0.1:8004`

### ğŸ“ æ–‡æœ¬åˆ†ç±»æ¥å£

* **URL Endpoint**: `/predict`
* **Method**: `POST`
* **Content-Type**: `application/json`

**è¯·æ±‚ä½“ç¤ºä¾‹ (JSON):**

```json
{
    "text": "SpaceX æ˜Ÿèˆ°ä»Šæ—¥æˆåŠŸå‘å°„ï¼Œå¼€å¯ç«æ˜Ÿç§»æ°‘æ–°ç¯‡ç« "
}
```

**å“åº”ä½“ç¤ºä¾‹ (JSON):**

```json
{
    "text": "SpaceX æ˜Ÿèˆ°ä»Šæ—¥æˆåŠŸå‘å°„...",
    "pred_class": "ç§‘æŠ€",
    "status": 200
}
```

## ğŸš€ è¿è¡ŒæŒ‡å—--æ¨¡å‹é‡åŒ– (How to Run)

### 1. å¼€å§‹è®­ç»ƒ (Train)

```bash
python train.py
```

æœ€ä½³æ¨¡å‹å°†ä¿å­˜åœ¨ `save_models/test_bertclassifer_model.pt`ã€‚

### 2. æ¨¡å‹é‡åŒ– (Quantization)

è¿è¡Œè„šæœ¬å°† FP32 æƒé‡å‹ç¼©ä¸º INT8 æ ¼å¼ï¼Œæ˜¾è‘—æå‡ CPU æ¨ç†é€Ÿåº¦ã€‚

```bash
python bert_model_quantization.py
```

### 3. é‡åŒ–é¢„æµ‹æ¨ç† (Predict)

é‡åŒ–ç®—å­ç›®å‰ä»…æ”¯æŒ CPUï¼Œæ¨ç†æ—¶éœ€å¼ºåˆ¶æŒ‡å®š `device='cpu'`ã€‚

```bash
python predict_quantization.py
```

---

## ğŸ’¡ æŠ€æœ¯æ·±åº¦æ€»ç»“ï¼šæ¨¡å‹åŠ è½½ä¸ä¿å­˜ç»éªŒ (Engineering Experience)



åœ¨å¼€å‘æ¨¡å‹å‹ç¼©ä¸é‡åŒ–åŠŸèƒ½æ—¶ï¼Œæœ¬é¡¹ç›®æ€»ç»“äº†ä»¥ä¸‹ PyTorch æ ¸å¿ƒç»éªŒï¼š

### 1. ä¸¤ç§ä¿å­˜æ–¹å¼çš„æƒè¡¡

* **`state_dict` (æ¨è)**ï¼š
  * ä»£ç ï¼š`torch.save(model.state_dict(), path)`ã€‚
  * ç‰¹ç‚¹ï¼šä»…ä¿å­˜å‚æ•°å­—å…¸ï¼Œæ–‡ä»¶ä½“ç§¯æœ€å°ã€‚ä¸ä¾èµ–ä»£ç ç›®å½•ç»“æ„ï¼Œè·¨è®¾å¤‡å…¼å®¹æ€§æœ€å¼ºã€‚
* **å…¨æ¨¡å‹ä¿å­˜**ï¼š
  * ä»£ç ï¼š`torch.save(model, path)`ã€‚
  * ç‰¹ç‚¹ï¼šä¿å­˜æ•´ä¸ªæ¨¡å‹å¯¹è±¡ã€‚ç”±äºé‡åŒ–åå±‚ç»“æ„å˜å¼‚ï¼Œå­˜å…¨é‡å¯é¿å…æ‰‹åŠ¨æ‰§è¡Œé‡åŒ–æµç¨‹ï¼Œä½†å¯¹æ–‡ä»¶å¤¹è·¯å¾„æœ‰æå¼ºä¾èµ–ã€‚

### 2. é‡åŒ–æ¨¡å‹çš„â€œè‚‰ä½“ä¸çµé­‚â€åŠ è½½é€»è¾‘

* **ç—›ç‚¹**ï¼šé‡åŒ–æ¨¡å‹åŒ…å«é¢å¤–çš„ `scale` å’Œ `zero_point` å‚æ•°ã€‚
* **æ­£ç¡®é¡ºåº**ï¼šå¦‚æœåŠ è½½çš„æ˜¯é‡åŒ–åçš„å‚æ•°å­—å…¸ï¼Œå¿…é¡»å…ˆå®ä¾‹åŒ–åŸå§‹æ¨¡å‹ï¼Œç„¶åæ‰‹åŠ¨æ‰§è¡Œ `quantize_dynamic` è®©ç»“æ„â€œå˜å¼‚â€ï¼Œæœ€åé€šè¿‡ `load_state_dict` æ³¨å…¥å‚æ•°ã€‚
* **æŠ¥é”™é¢„é˜²**ï¼šè‹¥ç›´æ¥å°†é‡åŒ–å‚æ•°åŠ è½½è¿›éé‡åŒ–å£³å­ï¼Œä¼šè§¦å‘ `KeyError` é”™è¯¯ã€‚

### 3. è®¡ç®—è®¾å¤‡çº¦æŸ (Device Constraint)

* **CPU ä¸“å±**ï¼šé‡åŒ–ç®—å­ç›®å‰ä»…æ³¨å†Œåœ¨ CPU ç«¯ï¼Œåœ¨ GPU ä¸Šè¿è¡Œé‡åŒ–æ¨¡å‹ä¼šæŠ›å‡º `NotImplementedError`ã€‚
* **è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨é¢„æµ‹è„šæœ¬ä¸­å¿…é¡»å¼ºåˆ¶æŒ‡å®š `device = 'cpu'`ï¼Œå¹¶å°†è¾“å…¥ Tensor åŒæ­¥ç§»è‡³ CPU å†…å­˜ã€‚

---

## â“ å¸¸è§é—®é¢˜

**Q1: æ˜¾å­˜æº¢å‡º (OOM) æ€ä¹ˆåŠï¼Ÿ**

A: è¯´æ˜æ˜¾å­˜çˆ†äº†ã€‚è¯·æ‰“å¼€ `config.py`ï¼Œå°† `self.batch_size` ä» 128 æ”¹ä¸º 64ï¼Œç”šè‡³ 32 æˆ– 16ã€‚

**Q2: æŠ¥é”™ `OSError: Can't load weights for 'bert-base-chinese'` æ€ä¹ˆåŠï¼Ÿ**

A: è¯´æ˜ä½ çš„ `bert-base-chinese` æ–‡ä»¶å¤¹é‡Œç¼ºå°‘æ–‡ä»¶ï¼Œæˆ–è€…æ–‡ä»¶åä¸å¯¹ã€‚è¯·æ£€æŸ¥æ˜¯å¦åŒ…å«äº† `pytorch_model.bin` ç­‰æ–‡ä»¶ï¼Œä¸”è·¯å¾„æ­£ç¡®ã€‚

**Q3: è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢ï¼Ÿ**

A: è¯·ç¡®ä¿ä½ å®‰è£…çš„æ˜¯ GPU ç‰ˆæœ¬çš„ PyTorchï¼Œå¹¶ä¸” `config.py` ä¸­çš„ `device` è¢«æ­£ç¡®è¯†åˆ«ä¸º `cuda`ã€‚

---

## ğŸ“„ ç‰ˆæƒè¯´æ˜

æœ¬é¡¹ç›®é‡‡ç”¨ MIT å¼€æºåè®®ã€‚

> 2026 Â© Developed by BERT-Team
